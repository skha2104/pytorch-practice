{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PyTorch basic code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/cryptography/hazmat/primitives/constant_time.py:26: CryptographyDeprecationWarning: Support for your Python version is deprecated. The next version of cryptography will remove support. Please upgrade to a 2.7.x release that supports hmac.compare_digest as soon as possible.\n",
      "  utils.DeprecatedIn23,\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create tensors\n",
    "x = torch.tensor(1., requires_grad=True)\n",
    "w = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)\n",
    "\n",
    "y = w * x + b\n",
    "\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print (x.grad)\n",
    "print (w.grad)\n",
    "print (b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 3)\n",
    "y = torch.randn(10, 2)\n",
    "\n",
    "linear = nn.Linear(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1064,  0.0450,  0.0905],\n",
      "        [ 0.0766, -0.5473, -0.2318]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4468,  0.5110], requires_grad=True)\n",
      "<bound method Linear.parameters of Linear(in_features=3, out_features=2, bias=True)>\n"
     ]
    }
   ],
   "source": [
    "print (linear.weight)\n",
    "print (linear.bias)\n",
    "print (linear.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4510, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = criterion(pred, y)\n",
    "print (loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dL/dw: ', tensor([[ 0.6260,  0.2559, -0.2910],\n",
      "        [ 0.3595, -0.5437,  0.0958]]))\n",
      "('dL/db: ', tensor([-0.8131,  0.8673]))\n"
     ]
    }
   ],
   "source": [
    "print ('dL/dw: ', linear.weight.grad)\n",
    "print ('dL/db: ', linear.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loss after 1 step optimization: ', 1.4509841203689575)\n"
     ]
    }
   ],
   "source": [
    "pred = linear(x)\n",
    "loss = criterion(pred, y)\n",
    "print ('Loss after 1 step optimization: ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([[1, 2], [3, 4]])\n",
    "y = torch.from_numpy(x)\n",
    "z = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "print (x)\n",
    "print (y)\n",
    "print (z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tutorial 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='../data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(), \n",
    "                                           download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='../data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = nn.Linear(input_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 2.2212\n",
      "Epoch [1/5], Step [200/600], Loss: 2.1054\n",
      "Epoch [1/5], Step [300/600], Loss: 2.0711\n",
      "Epoch [1/5], Step [400/600], Loss: 1.9754\n",
      "Epoch [1/5], Step [500/600], Loss: 1.8703\n",
      "Epoch [1/5], Step [600/600], Loss: 1.7974\n",
      "Epoch [2/5], Step [100/600], Loss: 1.7842\n",
      "Epoch [2/5], Step [200/600], Loss: 1.6721\n",
      "Epoch [2/5], Step [300/600], Loss: 1.6345\n",
      "Epoch [2/5], Step [400/600], Loss: 1.5703\n",
      "Epoch [2/5], Step [500/600], Loss: 1.5132\n",
      "Epoch [2/5], Step [600/600], Loss: 1.4802\n",
      "Epoch [3/5], Step [100/600], Loss: 1.3725\n",
      "Epoch [3/5], Step [200/600], Loss: 1.4573\n",
      "Epoch [3/5], Step [300/600], Loss: 1.3449\n",
      "Epoch [3/5], Step [400/600], Loss: 1.3838\n",
      "Epoch [3/5], Step [500/600], Loss: 1.2995\n",
      "Epoch [3/5], Step [600/600], Loss: 1.2269\n",
      "Epoch [4/5], Step [100/600], Loss: 1.2358\n",
      "Epoch [4/5], Step [200/600], Loss: 1.2477\n",
      "Epoch [4/5], Step [300/600], Loss: 1.1386\n",
      "Epoch [4/5], Step [400/600], Loss: 1.1630\n",
      "Epoch [4/5], Step [500/600], Loss: 1.1500\n",
      "Epoch [4/5], Step [600/600], Loss: 1.0787\n",
      "Epoch [5/5], Step [100/600], Loss: 1.0871\n",
      "Epoch [5/5], Step [200/600], Loss: 0.9964\n",
      "Epoch [5/5], Step [300/600], Loss: 1.0435\n",
      "Epoch [5/5], Step [400/600], Loss: 1.0399\n",
      "Epoch [5/5], Step [500/600], Loss: 0.9207\n",
      "Epoch [5/5], Step [600/600], Loss: 0.9810\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Rehape the images to (batch_size, input_size)\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 82%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    print ('Accuracy of the model on the 10000 test images: {}%'.format(100* correct / total))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural Network Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_size = 784\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.3767\n",
      "Epoch [1/5], Step [200/600], Loss: 0.2777\n",
      "Epoch [1/5], Step [300/600], Loss: 0.2290\n",
      "Epoch [1/5], Step [400/600], Loss: 0.1391\n",
      "Epoch [1/5], Step [500/600], Loss: 0.2500\n",
      "Epoch [1/5], Step [600/600], Loss: 0.2030\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0793\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0755\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0841\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0734\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0945\n",
      "Epoch [2/5], Step [600/600], Loss: 0.1132\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0964\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0834\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0436\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0488\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0633\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0741\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0256\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0443\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0303\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0255\n",
      "Epoch [4/5], Step [500/600], Loss: 0.1046\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0427\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0170\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0521\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0104\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0466\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0512\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0239\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 98%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print ('Accuracy of the model on the 10000 test images: {}%'.format(100* correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
